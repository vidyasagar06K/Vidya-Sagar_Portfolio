<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Skills</title>
    <link rel="stylesheet" href="style.css">
    <script src="action.js"></script>
</head>
<body>

     <!--header design-->
     <header class="header">
        <a href="#" class="logo">Portfolio.</a>
        <div class="bx bx-menu" id="menu-icon"></div>

        <nav class="navbar">
            <a href="#home" class="active">Home</a>
            <a href="#about">About</a>
            <a href="#education">Education</a>
            <a href="#projects">Projects</a>
            <a href="#experience">Experience</a>
            <a href="#contact">Contact Me</a>
        </nav>  

    </header>

    <!-- experience Section Design-->

    <section class="experience-description">
        <div class="exp-desc">
            <div class="container">
                <div class="exp-about">
<h2>Research Intern | National Institute of Technology (NIT), Warangal | Dec 2023 - Jan 2025</h2>
<h3>Project Title: </h3>
    <p>Artificial Intelligence-Based Smart Knee Brace</p>
<h3>Objective: </h3>
 <p>Developed a wearable system for measuring knee angles with respect to time using Raspberry Pi interfaced with a gyroscope sensor (MPU6050), with the aim of remote monitoring and analysis of knee conditions.</p>
<h3>Key Responsibilities and Achievements:</h3>
<p>1. Led a multidisciplinary team in designing and implementing the smart knee brace system, focusing on accuracy and reliability.</p>
<p>2. Integrated Raspberry Pi with gyroscope sensor for real-time data acquisition, enabling continuous monitoring of knee joint angles.</p>
<p>3. Utilized machine learning techniques, specifically Random Forest Algorithm, to categorize individuals' knee conditions as normal or abnormal based on collected data.</p>
<p>4. Implemented data processing algorithms to track knee flexion and extension range of motion, ensuring comprehensive analysis.</p>
<p>5. Successfully conducted testing and validation procedures, ensuring the functionality and effectiveness of the developed system.</p>
<p>6. Demonstrated strong problem-solving skills in overcoming technical challenges during system development, resulting in a functional prototype within the internship duration.</p>
<h3>Skills Developed:</h3>
<p>1. Hardware-software integration: Proficient in interfacing Raspberry Pi with sensors for data acquisition.</p>
<p>2. Data analysis and machine learning: Utilized Random Forest Algorithm for classification tasks and data-driven insights.</p>
<p>3. Collaboration and teamwork: Effectively collaborated with team members from diverse backgrounds to achieve project objectives within tight timelines.</p>
<p>4. Problem-solving: Demonstrated ability to troubleshoot technical issues and implement effective solutions, ensuring project success.</p>
<h3>Conclusion:</h3>
<p>The Artificial Intelligence-Based Smart Knee Brace project provided valuable hands-on experience in developing wearable healthcare technology solutions, leveraging artificial intelligence and sensor technologies. Demonstrated ability to contribute effectively in a fast-paced research and development environment, resulting in tangible outcomes within a short timeframe.</p>
<div class="exp">
    <a href="https://drive.google.com/file/d/1WsS8D-D0sbbpSvZy3dDuyb-fiImuNUYl/view?usp=drive_link" target="_blank" class="exp-btn">Certificate</a>
</div>  
        </div>
        </div>

            <div class="container">
    <div class="exp-about">
        <h2>Internship | Infosys Sprinboard | Nov 2024 - Jan 2025 </h2>
        <h3>Project Title: </h3>
        <p>Voice-Based Patient Call System</p>
        <h3>Introduction: </h3>
        <p>Our project, Voice-Based Patient Call System, is a healthcare solution designed to improve communication between patients and healthcare providers in hospitals. The primary goal is to provide patients with a simple, voice-enabled interface to request assistance, which is then efficiently routed to the concerned medical staff based on priority. This was a team project, and I was specifically responsible for implementing the AI-based components.</p>
        
        <h3>Problem Statement:</h3>
        <p>Hospitals often face challenges in managing patient requests efficiently, especially in critical situations where response time is crucial. Traditional systems like call buttons or manual logging are inefficient and prone to delays. This project aims to address this gap by leveraging AI and real-time communication technologies.</p>
        
        <h3>How It Works:</h3>
        <p>The workflow begins with the patient using the voice-based interface to make a request, such as asking for assistance or reporting an issue. The system processes this voice input, converts it into text using Azure Speech-to-Text services, and then uses Natural Language Processing (NLP) powered by Azure OpenAI to understand the intent and urgency of the request. Based on this analysis, the request is assigned a priority level—high or low—and dispatched in real-time to the nurse's smartphone app via Firebase notifications. The nurse can then take the required action, mark the task as completed, and update the status for the patient.</p>
        
        <h3>Technologies Used:</h3>
        <p>Frontend: React Native for a cross-platform mobile interface for both patients and nurses.</p>
        <p>Speech Processing: Azure Speech-to-Text for converting audio inputs to text.</p>
        <p>AI/NLP: Azure OpenAI for intent recognition and priority assignment.</p>
        <p>Backend: Node.js and Express.js for request routing and logic handling.</p>
        <p>Database: MongoDB for storing request data and task statuses.</p>
        <p>Real-Time Communication: Firebase for instant notifications to the nurse's app.</p>
        
        <h3>My Role:</h3>
        <p>As a team member, my primary responsibility was to develop the AI-based components of the project. Specifically, I implemented:</p>
        <p>1. Integration of Azure Speech-to-Text services for accurate voice recognition.</p>
        <p>2. NLP logic using Azure OpenAI to analyze the patient's intent and determine the priority of the requests.</p>
        <p>3. Ensured that the AI models provided accurate classifications and were robust enough to handle diverse voice inputs and scenarios.</p>
        
        <h3>Teamwork:</h3>
        <p>The project was a collaborative effort where each team member was responsible for specific components. While I focused on the AI and NLP aspects, other team members worked on:</p>
        <p>1. Developing the patient and nurse interfaces using React Native.</p>
        <p>2. Setting up the backend with Node.js and MongoDB for request handling.</p>
        <p>3. Implementing real-time notifications using Firebase.</p>
        <p>4. Ensuring smooth integration between all components through continuous testing and debugging.</p>
        
        <h3>Challenges and Solutions:</h3>
        <p>Challenge: Handling diverse accents and languages for voice recognition.<br>
        Solution: We fine-tuned Azure Speech-to-Text services to accommodate multiple accents commonly used in hospitals.</p>
        <p>Challenge: Ensuring accurate intent recognition for diverse requests.<br>
        Solution: We trained the Azure OpenAI models on a dataset of hospital-related phrases and requests to improve accuracy.</p>
        <p>Challenge: Real-time communication and scalability.<br>
        Solution: We implemented Firebase and designed the backend for scalability to handle multiple requests simultaneously.</p>
        
        <h3>Impact:</h3>
        <p>1. Improves response time for critical requests.</p>
        <p>2. Offers patients a user-friendly voice-based interface, reducing the need for physical buttons or manual processes.</p>
        <p>3. Streamlines communication between patients and nurses, enhancing overall hospital efficiency.</p>
        <p>4. Ensures high scalability and adaptability, making it suitable for various hospital environments.</p>
        
        <h3>Future Scope:</h3>
        <p>1. Add multi-language support to cater to diverse patient demographics.</p>
        <p>2. Implement predictive analytics to proactively identify patient needs.</p>
        <p>3. Integrate wearable devices for continuous patient monitoring.</p>
        
        <h3>Conclusion:</h3>
        <p>In summary, the Voice-Based Patient Call System is an innovative solution that leverages AI and real-time technologies to transform patient care. It addresses critical inefficiencies in traditional systems, providing a faster, smarter, and more reliable way to manage patient requests. My contribution to the AI components of this project helped ensure that patient requests were accurately understood and prioritized, which is vital in a healthcare setting.</p>
        
        <div class="exp">
            <a href="https://drive.google.com/file/d/1dDKm1EwdKtBLnQiH62Cn_cmdcJhcpIEq/view?usp=sharing" target="_blank" class="exp-btn">Certificate</a>
        </div>
    </div>
</div>

    </div>
    </section>

    <script>
        //toggle icon bars
    let menuIcon = document.querySelector('#menu-icon');
    let navbar = document.querySelector('.navbar');
    
    menuIcon.onclick = () =>{
        menuIcon.classList.toggle('bx-x');
        navbar.classList.toggle('active');
    } 
    //scroll sections
    let sections = document.querySelectorAll('section');
    let navlinks = document.querySelectorAll('header nav a');
    
    window.onscroll = () =>{
        sections.forEach(sec => {
            let top = window.scrollY;
            let offset = sec.offsetTop - 100;
            let height = sec.offsetHeight;
            let id = sec.getAttribute('id');
    
            if(top >= offset && top < offset + height) {
                   //active navbar links
                   navlinks.forEach(links => {
                    links.classList.remove('active');
                    document.querySelectorAll('header nav a[href*=' + id +' ]').classList.add('active');
                   });
            }
        });
    }
    
    window.onscroll = () =>{
        //sticky header
        let header = document.querySelector('header');
        header.classList.toggle('sticky', window.scrollY > 100);
     //remove toggle icon and navbar when clicks navbar links(scroll)
    menuIcon.classList.remove('bx-x');
    navbar.classList.remove('active');
    }
     </script>
</body>
</html>
